---
title: "Predicting Credit Risk for German Loan Applicants"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
    toc: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.align='center', message = FALSE, warning=FALSE)
```

## Quantitative Analysis Introduction

### Analysis Scenario

A loan manager is requesting a statistical model to help her department determine which loan applicants are creditable, i.e. most likely to repay their loans. An applicantâ€™s demographic and socio-economic profiles are considered by loan managers before a decision is made regarding his/her loan application. The manager's goal is to minimize risk and maximize profits for the bank's laon portfolio. The mananger shares the information that for the type of loans the model would apply to, if the borrower pays back the loan, the bank makes a profit of 35% of the loans value. On the other hand, if the borrower defaults, the bank's loss is 100%. The bank does not lose money for applicants who are rejected and the manager claims the model does that have to take into account opportunity cost for applicants who would have repaid the loan but were rejected.

Upon receiving this request, I decide to find a model for the manager that maximizes a Profit-Cost function given the provided data. The priority of the model fitting task will be prediction in this case as the manager has not specifically requested an interpretable model, but has requested a model with the best profit characteristics.

### Data Source

The loan manager gives you access to a sample of her department's loan data for 1000 applicants with the outcome of thier loans included. She claims the dataset was prepared by another analyst to be representative of the bank's actual customers. 

The data used in this project was originally provided by Dr. Hans Hofmann of the University of Hamburg and hosted by the UCI Machine Learning Repository. The specific version of the data used here (`credit`) was sourced from Penn State's graduate-level Appplied Data Mining and Statistical Learning 897D course.

## Round 1: Exploratory Data Analysis, Loss Function, and Initial Model Fit

### Summary

To begin, the data must be loaded into the session and the variables checked to determine their appropriate types. Then, the variance of each variable in relation to the response variable must be checked to ensure there are no zero variance predictors present. The profit/cost information must be programmed into a functional form that can be used to evalute the fitted models. Finally, an initial set of models is fit to the data to determine how best to proceed. 

### Load Packages

```{r load-pkgs}
library(data.table)
library(gmodels)
library(DT)
library(gridExtra)
library(pander)
library(stringr)
library(woe)
library(caret)
library(tidyverse)
```


### Load the Data

Many of the variable names are invalid such as "Duration of Credit (month)". The whitespaces and invalid parenthesis characters will likely cause problems in any programmatic use of these predictors.

```{r load-data}
# Load the data to a tibble dataframe using data.table::fread
credit = fread("german_credit.csv") %>% 
                    tbl_df

# Convert all the variable names to snake_case by making them all lower case, removing invalid characters, and replacing spaces with an underscore
names(credit) = names(credit) %>% 
                    tolower %>% 
                    str_replace_all("[ /]", "_") %>% 
                    str_replace_all("[(&)]", "")

# Show a preview
credit %>% datatable(style="bootstrap")
```


### Variable Classifications

The first step in exploring the data is determine what type of variables are present in the data. Are the variables categorical or quantitative? If they are categorical are they binary or do they have multiple levels. If they are quantitative, are they discrete or continuous? 

```{r var-classification}
# Force all variables to factors the ncount the number of unique levels present and summarize
credit_types = credit %>% 
                    mutate_all(factor) %>% 
                    map(levels) %>% 
                    map(length) %>% 
                    tbl_df %>% 
                    gather(variable, n_unique) %>% 
                    arrange(n_unique) %>% 
                    mutate(binary = n_unique==2, categorical = n_unique <=10, continuous = n_unique > 10)

# Preview the data
datatable(credit_types, style="bootstrap")
```

### Examing the Response Variable

```{r}
CrossTable(credit$creditability)
```

```{r}
credit$creditability = factor(credit$creditability)
levels(credit$creditability) = make.names(levels(factor(credit$creditability)))   
credit$creditability = factor(credit$creditability, levels=c("X1", "X0"))
```

### Binary Variables
```{r}
binary_names = credit_types %>% filter(binary) %>% .$variable
credit = credit %>% mutate_at(binary_names, factor)
```

```{r near-zero-var, results = "asis", cache=TRUE}
# Identify near zero variance predictors
print("Any empty conditional distributions in at least one class of Creditability?")
length(checkConditionalX(credit[,binary_names]%>%select(-creditability), credit$creditability)) > 0
nzv = nearZeroVar(credit[,binary_names], names = TRUE, saveMetrics = TRUE) %>% select(-percentUnique)
indexes = rownames(nzv)
pandoc.table(data.frame(indexes = indexes, nzv) %>% tbl_df %>% arrange(desc(freqRatio)))
```

### Non-binary Categorical Variables
```{r}
nb_names = credit_types %>% filter(!binary,categorical) %>% .$variable
credit = credit %>% mutate_at(nb_names, factor)
```


```{r near-zero-var, results = "asis", cache=TRUE}
# Identify near zero variance predictors
print("Any empty conditional distributions in at least one class of Creditability?")
length(checkConditionalX(credit[,nb_names], credit$creditability)) > 0
nzv = nearZeroVar(credit[,nb_names], names = TRUE, saveMetrics = TRUE) %>% select(-percentUnique)
indexes = rownames(nzv)
pandoc.table(data.frame(indexes = indexes, nzv) %>% tbl_df %>% arrange(desc(freqRatio)))
```



### Continous Variables

```{r results="asis"}
quant_names = credit_types %>% filter(continuous) %>% .$variable

quant_summary = function(data, vector_name) {
    data %>% summarize_at(vector_name, funs(MIN=min,Q1 = quantile(., 0.25), MEAN = mean, MEDIAN = median,Q3 = quantile(., 0.75), MAX=max,IQR = IQR, STDEV = sd)) %>%
                                mutate(SKEW = ifelse(MEAN > MEDIAN, "RIGHT", "LEFT"))
}

data.frame(Predictor = quant_names,
                        bind_rows(
                            quant_summary(credit, quant_names[1]),
                            quant_summary(credit, quant_names[2]),
                            quant_summary(credit, quant_names[3]))) %>% pandoc.table(split.tables=Inf)
```


```{r fig.width=12}
left = ggplot(credit, aes(duration_of_credit_month, fill=creditability, color=creditability)) + geom_density(alpha=0.5)
middle= ggplot(credit, aes(age_years , fill=creditability, color=creditability)) + geom_density(alpha=0.5)
center=ggplot(credit, aes(credit_amount , fill=creditability, color=creditability)) + geom_density(alpha=0.5)
grid.arrange(left,middle,center, ncol=1)
```

### Loss Function

```{r}
Profit35 = function(actual, pred, positive=NULL) {
    Confusion_DF <- MLmetrics::ConfusionDF(pred, actual)
    if (is.null(positive) == TRUE) 
        positive <- as.character(Confusion_DF[1, 1])
    TP <- as.integer(subset(Confusion_DF, y_true == positive & 
        y_pred == positive)["Freq"])
    FP <- as.integer(sum(subset(Confusion_DF, y_true != positive & 
        y_pred == positive)["Freq"]))
    val_35 = (TP / sum(Confusion_DF$Freq))*0.35 + (FP / sum(Confusion_DF$Freq))*-1
    return(val_35)
}
p35 = function(data, lev = NULL, model = NULL) {
  p35_val <- Profit35(data$obs, data$pred, lev[1])
  spec = MLmetrics::Specificity(data$obs, data$pred)
  acc = MLmetrics::Accuracy(data$pred, data$obs)
  c(Accuracy = acc, Specificity= spec, P35 = p35_val)
}

p35(data.frame(obs = credit$creditability, pred = factor(c(rep("X1", 999), rep("X0",1)))))
p35(data.frame(obs = credit$creditability, pred = credit$creditability))
```



### Exploring Inital Model Space

```{r}
set.seed(123)
repeatedResamples = function(y, k = 10, reps=10) {
    suppressWarnings(
    for (idx in 1:reps) {
        # Create custom indices: myFolds
        myFolds <- createCVFolds(y, k = k)

        # Create reusable trainControl object: myControl
        myControl <- trainControl(summaryFunction = p35,
                                  classProbs = TRUE, # IMPORTANT!
                                  verboseIter = FALSE,
                                  savePredictions = TRUE,
                                  index = myFolds
                                 )

        log_fit = train(creditability ~ ., 
                        method = 'glm', 
                        family = 'binomial', 
                        data = credit,
                        trControl = myControl,
                        metric = "P35")
        
        lda_fit = train(creditability ~ ., 
                        method = 'lda',
                        show = FALSE,
                        data = credit,
                        trControl = myControl,
                        metric = "P35")
        
        tuneGridRF = data.frame(
                mtry=54
            )
        
        rf_fit = train(creditability ~ ., 
                        method = 'rf', 
                        data = credit,
                        trControl=myControl,
                        tuneGrid=tuneGridRF,
                        metric = "P35")
        
        tuneGridXGB <- expand.grid(
            nrounds=550,
            max_depth = 1,
            eta = 0.2,
            gamma = 0.2,
            colsample_bytree = 0.65,
            subsample = 0.95,
            min_child_weight = 2)
        
        xgb_fit = train(creditability ~ ., 
                        method = 'xgbTree',
                        data = credit,
                        trControl= myControl,
                        tuneGrid = tuneGridXGB,
                        metric = "P35")

        # Create model_list
        model_list <- list(log = log_fit, lda = lda_fit, rf = rf_fit, xgb = xgb_fit)

        if (idx == 1) {
            # Pass model_list to resamples(): resamples
            resamples <- resamples(model_list)
        }
        else {
            current_resample = resamples(model_list)
            resamples$values = bind_rows(resamples$values, current_resample$values)
        }
        
    }
    )
       return(resamples) 
    
}
report_dat = repeatedResamples(credit$creditability)
summary(report_dat)
```


## Round Two: Exploring Regularized Models 

```{r}
set.seed(123)
repeatedResamples = function(y, data, k = 10, reps=10) {
    suppressWarnings(
    for (idx in 1:reps) {
         # Create custom indices: myFolds
         myFolds <- createCVFolds(y, k = k)

        # Create reusable trainControl object: myControl
        myControl <- trainControl(summaryFunction = p35,
                                  classProbs = TRUE, # IMPORTANT!
                                  verboseIter = FALSE,
                                  savePredictions = TRUE,
                                  index = myFolds
                                 )

       log_reg_fit = train(creditability ~ ., 
                method = 'regLogistic', 
                data = data,
                trControl=myControl,
                metric = "P35")

        rlda_fit = train(creditability ~ ., 
                method = 'rlda', 
                data = data,
                trControl=myControl,
                metric = "P35")
        
        tuneGridRF = data.frame(
                mtry=54
            )
        
        rf_fit = train(creditability ~ ., 
                        method = 'rf', 
                        data = credit,
                        trControl=myControl,
                        tuneGrid=tuneGridRF,
                        metric = "P35")
        
        tuneGridXGB <- expand.grid(
            nrounds=150,
            max_depth = 1,
            eta = 0.45,
            gamma = 0.2,
            colsample_bytree = 0.65,
            subsample = 0.95,
            min_child_weight = 2)

        xgb_reg_fit = train(creditability ~ ., 
                method = 'xgbTree',
                data = data,
                trControl= myControl,
                tuneGrid = tuneGridXGB,
                alpha = 0.45,
                metric = "P35")

        # Create model_list
        model_list <- list(log_reg = log_reg_fit, rlda = rlda_fit, rf = rf_fit, xgb=xgb_reg_fit)

        if (idx == 1) {
            # Pass model_list to resamples(): resamples
            resamples <- resamples(model_list)
        }
        else {
            current_resample = resamples(model_list)
            resamples$values = bind_rows(resamples$values, current_resample$values)
        }
        
    }
    )
       return(resamples) 
    
}
    
fit_results = repeatedResamples(credit$creditability, credit)
summary(fit_results)
```

## Round 3: Feature Engineering for Dimension Reduction

```{r}
dummies <- dummyVars(creditability ~ ., data = credit)
dummies = predict(dummies, newdata = credit) %>% tbl_df
dummies$creditability = credit$creditability
```

```{r fig.height=10}
set.seed(123)
IV = iv.mult(as.data.frame(dummies),"creditability", summary = TRUE, verbose = FALSE)
IV %>% iv.plot.summary
```


```{r}
set.seed(123)
X = dummies %>% dplyr::select(-creditability)
library(xgboost)
# Prep data for xgboost
x_num = as.matrix(X) %>% apply(2,as.numeric)
x_label = as.numeric(as.character(ifelse(dummies$creditability == "X1", 1, 0)))
x_matrix = xgboost::xgb.DMatrix(data = x_num, label = x_label)
# Fit the model
bst <- xgboost(data = x_matrix,
               nround = 150, # default 100
               eta = 0.45, # default 0.3
               max.depth = 1, # default = 6 
               gamma = 0.2, # default 0, if train error >>> test error, bring gamma into action
               min_child_weight = 2, # default = 1
               subsample = 0.95, # default = 1
               colsample_bytree = 0.65, # default 1
               objective = "binary:logistic",
               alpha=0.45,
               eval_metric = "auc")

# plot the most important features
xgb_import = xgb.importance(colnames(x_num, do.NULL = TRUE, prefix = "col"), model = bst)
xgb.plot.importance(xgb.importance(colnames(x_num, do.NULL = TRUE, prefix = "col"), model = bst), top_n = 71)
```


```{r}
combo = IV %>% left_join(xgb_import, by = c("Variable" = "Feature")) 
combo[is.na(combo)] = 0

combo %>% dplyr::select(Variable, Strength, InformationValue, Gain) %>% mutate(InformationValue = as.numeric(scale(InformationValue)), Gain = as.numeric(scale(Gain)), mean = InformationValue + Gain / 2) %>% arrange(Variable)
```

```{r}
credit_select = credit
# account_balance - c(2,3) 1,4
# most_valueable_asset - c(2,3) 1,4
# payment_status_of_previous_credit - c(0,1,2,3) 4
# purpose - c(2,4,5,6,8,9,10) 3,1,0
# sex__marital_status - c(1,4) 2,3
# value_savings_stocks - c(2,3,4) 1, 5

levels(credit_select$account_balance) = c("1","2","2","3")
levels(credit_select$most_valuable_available_asset) = c("1","2","2","3")
levels(credit_select$payment_status_of_previous_credit) = c("1","1","1","1","2")
levels(credit_select$purpose) = c("0", "1", "2", "3", "2", "2", "2", "2", "2", "2")
levels(credit_select$sex__marital_status) = c("1","2","3","1")
levels(credit_select$value_savings_stocks) = c("1","2","2","2","3")

# Eliminate?
# concurrent_credits
# duration_in_current_address
# foreign_worker
# guarantors
# installment_per_cent
# length_of_current_employment
# no_of_credits_at_this_bank
# no_of_dependents
# occupation
# telephone
credit_select = credit_select %>% dplyr::select(-concurrent_credits, -duration_in_current_address, -foreign_worker, -guarantors, -instalment_per_cent, -length_of_current_employment, -no_of_credits_at_this_bank, -no_of_dependents, occupation, telephone)
```


```{r}
set.seed(123)
repeatedResamples = function(y, data, k = 10, reps=10) {
    suppressWarnings(
    for (idx in 1:reps) {
         # Create custom indices: myFolds
         myFolds <- createCVFolds(y, k = k)

        # Create reusable trainControl object: myControl
        myControl <- trainControl(summaryFunction = p35,
                                  classProbs = TRUE, # IMPORTANT!
                                  verboseIter = FALSE,
                                  savePredictions = TRUE,
                                  index = myFolds
                                 )

        log_fit = train(creditability ~ ., 
                method = 'glm', 
                family = 'binomial', 
                data = data,
                trControl=myControl,
                metric = "P35")
        
        tuneGridRF = data.frame(
                mtry=21
            )
        
        rf_fit = train(creditability ~ ., 
                        method = 'rf', 
                        data = credit,
                        trControl=myControl,
                        tuneGrid=tuneGridRF,
                        metric = "P35")
        
        log_reg_fit = train(creditability ~ ., 
                method = 'regLogistic', 
                data = data,
                trControl=myControl,
                metric = "P35")

        rlda_fit = train(creditability ~ ., 
                method = 'rlda', 
                data = data,
                trControl=myControl,
                metric = "P35")
        
        tuneGridXGB <- expand.grid(
                            nrounds=150,
                            max_depth = 4,
                            eta = 0.1,
                            gamma = 0,
                            colsample_bytree = 0.7,
                            subsample = 0.75,
                            min_child_weight = 1)

        xgb_fit = train(creditability ~ ., 
                method = 'xgbTree',
                data = data,
                trControl= myControl,
                tuneGrid = tuneGridXGB,
                metric = "P35")

        # Create model_list
        model_list <- list(log = log_fit, rf=rf_fit, rf_cut = rf_fit, xgb=xgb_fit, log_reg = log_reg_fit, rlda=rlda_fit)

        if (idx == 1) {
            # Pass model_list to resamples(): resamples
            resamples <- resamples(model_list)
        }
        else {
            current_resample = resamples(model_list)
            resamples$values = bind_rows(resamples$values, current_resample$values)
        }
        
    }
    )
       return(resamples) 
    
}
fit_results_less_dims = repeatedResamples(credit_select$creditability, credit_select)
summary(fit_results_less_dims)
```

## Round 4: Prediction Probability Cutoff Threshold Optimization

```{r}

```


## Final Model Selection and Metrics

```{r}
rlda_fit = train(creditability ~ ., 
                method = 'rlda', 
                data = credit_select,
                trControl = myControl,
                metric = "P35")
```



## Conclusion
```{r}
set.seed(123)
repeatedResamples = function(y, data, k = 10, reps=10) {
    suppressWarnings(
    for (idx in 1:reps) {
         # Create custom indices: myFolds
         myFolds <- createFolds(y, k = k)

        # Create reusable trainControl object: myControl
        myControl <- trainControl(summaryFunction = p35,
                                  classProbs = TRUE, # IMPORTANT!
                                  verboseIter = FALSE,
                                  savePredictions = TRUE,
                                  index = myFolds
                                 )

      
        rf_fit = train(creditability ~ ., 
                method = 'ranger',
                tuneGrid = expand.grid(splitrule="maxstat",
                alpha = 0.5),
                control = ranger.control(minsplit = 1, minbucket = 1)
                data = data,
                trControl=myControl,
                metric = "P35")
        
        rf2_fit = train(creditability ~ ., 
                method = 'ranger',
                tuneGrid = expand.grid(splitrule="maxstat",
                alpha = 0.85),
                data = data,
                trControl=myControl,
                metric = "P35")


        rlda_fit = train(creditability ~ ., 
                method = 'rlda', 
                data = data,
                trControl=myControl,
                metric = "P35")
        
        # Create model_list
        model_list <- list(rf=rf_fit, rf2=rf2_fit,rlda=rlda_fit)

        if (idx == 1) {
            # Pass model_list to resamples(): resamples
            resamples <- resamples(model_list)
        }
        else {
            current_resample = resamples(model_list)
            resamples$values = bind_rows(resamples$values, current_resample$values)
        }
        
    }
    )
       return(resamples) 
    
}
fit_results = repeatedResamples(credit_select$creditability, credit_select)
summary(fit_results)
```

